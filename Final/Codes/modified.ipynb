{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg \n",
    "from PIL import Image\n",
    "import os \n",
    "import skimage.io as io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE ONLY DATA USED IN THIS PROGRAM IS all_mias_scans.h5\n",
    "The problem of 322 and 330 is that: the class column is the label of the abnormality in the images which MAY NOT BE ONLY ONE. So some images has two labels because it has two tumors with different class. The classes are:\n",
    "CALC Calcification CIRC Well-defined/circumscribed masses SPIC Spiculated masses MISC Other, ill-defined masses ARCH Architectural distortion ASYM Asymmetry NORM Normal\n",
    "where only NORM means nothing abnormal happened, the others all says this image has a tumor with certain class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear2(lenaaa):\n",
    "#This function is to clear the white line and bright spot of the images\n",
    "    m = 0\n",
    "    n = 0\n",
    "    for i in range(0,1024):\n",
    "        for j in range(512,1024):\n",
    "            if lenaaa[i,j]==0:\n",
    "                lenaaa[i,j:1024]=0\n",
    "    return lenaaa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "\n",
    "'''通过方差的百分比来计算将数据降到多少维是比较合适的，\n",
    "函数传入的参数是特征值和百分比percentage，返回需要降到的维度数num'''\n",
    "def eigValPct(eigVals,percentage):\n",
    "    \n",
    "    \n",
    "#This cell is simply a function i write to replace the PCA in sklearn,ignore the chinese words.\n",
    "\n",
    "\n",
    "    sortArray=sort(eigVals) #使用numpy中的sort()对特征值按照从小到大排序\n",
    "    sortArray=sortArray[-1::-1] #特征值从大到小排序\n",
    "    arraySum=sum(sortArray) #数据全部的方差arraySum\n",
    "    tempSum=0\n",
    "    num=0\n",
    "    for i in sortArray:\n",
    "        tempSum+=i\n",
    "        num+=1\n",
    "        if tempSum>=arraySum*percentage:\n",
    "            return num\n",
    "\n",
    "'''pca函数有两个参数，其中dataMat是已经转换成矩阵matrix形式的数据集，列表示特征；\n",
    "其中的percentage表示取前多少个特征需要达到的方差占比，默认为0.9'''\n",
    "def pca(dataMat,percentage=0.8):\n",
    "    meanVals=mean(dataMat,axis=0)  #对每一列求平均值，因为协方差的计算中需要减去均值\n",
    "    meanRemoved=dataMat-meanVals\n",
    "    covMat=cov(meanRemoved,rowvar=0)  #cov()计算方差\n",
    "    eigVals,eigVects=linalg.eig(mat(covMat))  #利用numpy中寻找特征值和特征向量的模块linalg中的eig()方法\n",
    "    k=4 #要达到方差的百分比percentage，需要前k个向量\n",
    "    eigValInd=argsort(eigVals)  #对特征值eigVals从小到大排序\n",
    "    eigValInd=eigValInd[:-(k+1):-1] #从排好序的特征值，从后往前取k个，这样就实现了特征值的从大到小排列\n",
    "    redEigVects=eigVects[:,eigValInd]   #返回排序后特征值对应的特征向量redEigVects（主成分）\n",
    "    lowDDataMat=meanRemoved*redEigVects #将原始数据投影到主成分上得到新的低维数据lowDDataMat\n",
    "    reconMat=(lowDDataMat*redEigVects.T)+meanVals   #得到重构数据reconMat\n",
    "    return lowDDataMat,reconMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/Users/nizheng/Desktop/mias-mammography/all_mias_scans.h5', 'r') as scan_h5:\n",
    "    bg_info = scan_h5['BG'][:]\n",
    "    class_info = scan_h5['CLASS'][:]\n",
    "    # low res scans\n",
    "    scan_lr = scan_h5['scan'][:]\n",
    "    index_lr = scan_h5['REFNUM'][:]\n",
    "    x_lr = scan_h5['X'][:]\n",
    "    y_lr = scan_h5['Y'][:]\n",
    "    r_lr = scan_h5['RADIUS'][:]\n",
    "#read images\n",
    "index = np.zeros(330)\n",
    "coll = scan_lr\n",
    "for i in range(0,330):\n",
    "    index[i] = int(index_lr[i][3:6])\n",
    "a = np.where(index%2 == 1)\n",
    "for k in a:\n",
    "    for i in range(0,1024):\n",
    "        for j in range(0,512):\n",
    "            u = coll[k,i,j]\n",
    "            coll[k,i,j] = coll[k,i,1023-j]\n",
    "            coll[k,i,1023-j] = u\n",
    "#change right to left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127.0 687.0\n",
      "230.0 632.0\n",
      "159.0 898.0\n",
      "149.0 994.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "994.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss=1023-x_lr[np.where(index%2 == 1)]\n",
    "ss2=1023-y_lr[np.where(index%2 == 1)]\n",
    "print(min(x_lr[np.where(index%2 == 0)]),max(x_lr[np.where(index%2 == 0)]))\n",
    "print(min(ss),max(ss))\n",
    "\n",
    "print(min(ss2),max(ss2))\n",
    "print(min(y_lr[np.where(index%2 == 0)]),max(y_lr[np.where(index%2 == 0)]))\n",
    "max(y_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll[coll<40]=0\n",
    "np.min(coll[coll>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,330):\n",
    "    coll[i] = clear2(coll[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image processing for some rare occasions\n",
    "coll[287,960:1024,0:1024] = np.zeros((64,1024))\n",
    "coll[287,400:1024,790:1024] = np.zeros((1,1))\n",
    "coll[287,880:1000,500:600] = np.zeros((1,1))\n",
    "coll[281,960:1024,0:1024] = np.zeros((64,1024))\n",
    "coll[281,400:1024,790:1024] = np.zeros((1,1))\n",
    "coll[281,900:1000,600:700] = np.zeros((1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in a:\n",
    "    for i in range(0,1024):\n",
    "        for j in range(0,512):\n",
    "            u = coll[k,i,j]\n",
    "            coll[k,i,j] = coll[k,i,1023-j]\n",
    "            coll[k,i,1023-j] = u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nizheng/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#using pca to do dimensional deduction\n",
    "mmmm = np.zeros((330,1024,4))\n",
    "for i in range(0,330):\n",
    "    mmmm[i] = pca(coll[i])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "badindex = np.where(~isnan(x_lr))\n",
    "goodindex = np.where(isnan(x_lr))\n",
    "y_bad = y_lr[badindex]\n",
    "x_bad = x_lr[badindex]\n",
    "r_bad = r_lr[badindex]\n",
    "pic_bad = scan_lr[badindex]\n",
    "pic_good = scan_lr[goodindex]\n",
    "\n",
    "r=20\n",
    "nbad=2\n",
    "ngood=5\n",
    "\n",
    "core_bad=np.zeros((len(x_bad)*nbad,r*2,r*2))\n",
    "core_good=np.zeros((len(pic_good)*ngood,r*2,r*2))\n",
    "move=np.array([1023,1023])\n",
    "\n",
    "for i in range(len(x_bad)):\n",
    "    core_bad[i*nbad] = pic_bad[i,(1023-int(y_bad[i])-r):(1023-int(y_bad[i])+r),(int(x_bad[i])-r):(int(x_bad[i])+r)]\n",
    "    for j in range(1,nbad):\n",
    "        move=np.array([1023,1023])\n",
    "        while move[0]+int(y_bad[i])-r<0 or move[0]+int(y_bad[i])+r>1023 or int(x_bad[i])-r+move[1]<0 or int(x_bad[i])-r+move[1]>1023:\n",
    "            move=np.random.randint(-10,10,2)\n",
    "        core_bad[i*nbad+j]=pic_bad[i,(1023-int(y_bad[i])+move[0]-r):(1023-int(y_bad[i])+move[0]+r),(int(x_bad[i])+move[1]-r):(int(x_bad[i])+move[1]+r)]\n",
    "        \n",
    "        \n",
    "for i in range(len(pic_good)):\n",
    "    for j in range(ngood):\n",
    "        while ~core_good[i*ngood+j].all():\n",
    "            index_rand=np.random.randint(r,1023-r,2)\n",
    "            core_good[i*ngood+j] = pic_good[i,(index_rand[0]-r):(index_rand[0]+r),(index_rand[1]-r):(index_rand[1]+r)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'BALA', b'NORM'], dtype='|S4')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#train test split\n",
    "mmmm = np.zeros((len(core_bad)+len(core_good),2*r,2*r))\n",
    "mmmm[0:len(core_bad),]=core_bad\n",
    "mmmm[len(core_bad):len(core_bad)+len(core_good),]=core_good\n",
    "scan_lr_flat = mmmm.reshape((mmmm.shape[0],-1))\n",
    "\n",
    "class_info = class_info[np.append(badindex[0].repeat(nbad),goodindex[0].repeat(ngood))]\n",
    "for i in range(len(mmmm)):\n",
    "    if class_info[i] != class_info[len(class_info)-1]:\n",
    "        class_info[i] = 'BALA'\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "class_le = LabelEncoder()\n",
    "class_le.fit(class_info)\n",
    "class_vec = class_le.transform(class_info)\n",
    "class_le.classes_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (646, 1600)\n",
      "Testing (647, 1600)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "idx_vec = np.arange(scan_lr_flat.shape[0])\n",
    "x_train, x_test, y_train, y_test, idx_train, idx_test = train_test_split(scan_lr_flat, \n",
    "                                                    class_vec, \n",
    "                                                    idx_vec,\n",
    "                                                   test_size = 0.5,\n",
    "                                                   stratify = class_vec)\n",
    "print('Training', x_train.shape)\n",
    "print('Testing', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505.0 793.0\n",
      "125.0 994.0\n"
     ]
    }
   ],
   "source": [
    "print(median(x_bad),max(x_bad))\n",
    "print(min(y_bad),max(y_bad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=np.zeros(((1024//r)*(1024//r),2*r,2*r))\n",
    "\n",
    "pic=pic_bad[109]\n",
    "for i in range(1024//r-1):\n",
    "    for j in range(1024//r-1):\n",
    "        Xtest[i*1024//r+j]=pic[(i*r):(i*r+2*r),(j*r):(j*r+2*r)]\n",
    "\n",
    "Temp=np.zeros(len(Xtest))\n",
    "for i in range(len(Xtest)):\n",
    "    if Xtest[i].all():\n",
    "        Temp[i]=1\n",
    "Xtest=Xtest[np.where(Temp==1)[0]]  \n",
    "x_test=Xtest.reshape(Xtest.shape[0],-1)\n",
    "y_test=np.array([1]).repeat(Xtest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss_train=np.zeros((len(core_bad)+len(core_good),40,4))\n",
    "for i in range(0,len(core_bad)+len(core_good)):\n",
    "    sss_train[i] = pca(mmmm[i])[0]\n",
    "x_train=sss_train.reshape(sss_train.shape[0],-1)\n",
    "y_train=class_vec\n",
    "x_test=sss_train.reshape(sss_train.shape[0],-1)\n",
    "y_test=class_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = np.zeros((960,40,4))\n",
    "for i in range(0,960):\n",
    "    sss[i] = pca(Xtest[i])[0]\n",
    "x_test=sss.reshape(sss.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1228,)"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a better report instead of only accuracy\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "creport = lambda gt_vec,pred_vec: classification_report(gt_vec, pred_vec, \n",
    "                                                        target_names = [x.decode() for x in \n",
    "                                                                        class_le.classes_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 84.39%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       BALA       0.80      0.29      0.42       129\n",
      "       NORM       0.85      0.98      0.91       518\n",
      "\n",
      "avg / total       0.84      0.84      0.81       647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#knn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "print('Accuracy %2.2f%%' % (100*accuracy_score(y_test, y_pred)))\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1194\n",
      "1020.0\n"
     ]
    }
   ],
   "source": [
    "if model_acc*len(y_pred)<sum(y_pred):\n",
    "    print(1)\n",
    "else:\n",
    "    print(0)\n",
    "print(sum(y_pred))\n",
    "print(model_acc*len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_acc=float(asD.capitalize()[125:129])\n",
    "model_acc\n",
    "asD=creport(y_test, y_pred)\n",
    "float(asD.capitalize()[125:129])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([], dtype=int64),) (array([  1,  23,  24,  52, 112, 113, 114, 142, 143]),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.where(y_test==0),np.where(y_pred==0))\n",
    "np.where(y_test==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 84.70%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       BALA       0.66      0.48      0.56       129\n",
      "       NORM       0.88      0.94      0.91       518\n",
      "\n",
      "avg / total       0.84      0.85      0.84       647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(x_train, y_train)\n",
    "y_pred = rfc.predict(x_test)\n",
    "print('Accuracy %2.2f%%' % (100*accuracy_score(y_test, y_pred)))\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Accuracy 57.03%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       BALA       0.19      0.36      0.25       129\n",
      "       NORM       0.80      0.62      0.70       518\n",
      "\n",
      "avg / total       0.68      0.57      0.61       647\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel=\"linear\",C=0.8)\n",
    "clf.fit(x_train, y_train)\n",
    "print (clf.score(x_train, y_train))  # 精度\n",
    "y_pred = clf.predict(x_test)\n",
    "print('Accuracy %2.2f%%' % (100*accuracy_score(y_test, y_pred)))\n",
    "print(creport(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 1116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pic_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_good=np.zeros(len(pic_good))\n",
    "ratio_good=np.zeros(len(pic_good))\n",
    "for n in range(len(pic_good)):\n",
    "    Xtest=np.zeros(((1024//r)*(1024//r),2*r,2*r))\n",
    "\n",
    "    pic=pic_good[n]\n",
    "    for i in range(1024//r-1):\n",
    "        for j in range(1024//r-1):\n",
    "            Xtest[i*1024//r+j]=pic[(i*r):(i*r+2*r),(j*r):(j*r+2*r)]\n",
    "\n",
    "    Temp=np.zeros(len(Xtest))\n",
    "    for i in range(len(Xtest)):\n",
    "        if Xtest[i].all():\n",
    "            Temp[i]=1\n",
    "    Xtest=Xtest[np.where(Temp==1)[0]]  \n",
    "    x_test=Xtest.reshape(Xtest.shape[0],-1)\n",
    "    y_test=np.array([0]).repeat(Xtest.shape[0])\n",
    "\n",
    "    #a better report instead of only accuracy\n",
    "    from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "    creport = lambda gt_vec,pred_vec: classification_report(gt_vec, pred_vec, \n",
    "                                                            target_names = [x.decode() for x in \n",
    "                                                                            class_le.classes_])\n",
    "\n",
    "    #knn\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    #print('Accuracy %2.2f%%' % (100*accuracy_score(y_test, y_pred)))\n",
    "    #print(creport(y_test, y_pred))\n",
    "\n",
    "    sum_good[n]=sum(y_pred==0)\n",
    "    ratio_good[n]=sum_good[n]/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  4.,  6.,  6., 12., 10., 17., 11., 19., 15.,  9., 11., 17.,\n",
       "        18., 13.,  9.,  3.,  3.,  7.,  5.,  4.,  3.,  3.,  2.,  0.,  0.,\n",
       "         1.,  0.,  0.,  0.]),\n",
       " array([0.1       , 0.11333333, 0.12666667, 0.14      , 0.15333333,\n",
       "        0.16666667, 0.18      , 0.19333333, 0.20666667, 0.22      ,\n",
       "        0.23333333, 0.24666667, 0.26      , 0.27333333, 0.28666667,\n",
       "        0.3       , 0.31333333, 0.32666667, 0.34      , 0.35333333,\n",
       "        0.36666667, 0.38      , 0.39333333, 0.40666667, 0.42      ,\n",
       "        0.43333333, 0.44666667, 0.46      , 0.47333333, 0.48666667,\n",
       "        0.5       ]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 847,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEYRJREFUeJzt3X2MZXV9x/H3R3xoSmlFGVGBYbWlNGAUdYraqsUn5EFFK22hD4JiVo2mNTVpsDba6B+lbdS0xUi3StDGgqktloYF3fpQNBF1ocuTiizrGneloEBBfMzqt3/M2Xgd7szcvefeubP83q/kZs75nd855ztndz5z5px7fjdVhSSpHQ+adQGSpLVl8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5Ia8+BZFzDMIYccUhs2bJh1GZK037jmmmu+XVVzo/Rdl8G/YcMGtm7dOusyJGm/keTro/b1Uo8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVmXT65q9nacO7lI/Xbed6pU65E0jR4xi9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQ7ZoAc0h5+Q7m/V4E9yIfAi4I6qekLX9mHg6K7Lw4H/q6rjhqy7E/gO8GNgT1UtTKhuSdKYRjnjvwg4H/jg3oaq+r2900neCdyzwvrPqapvj1ugJGmyVg3+qroqyYZhy5IE+F3guZMtS5I0LX1v7j4LuL2qbllmeQEfT3JNko099yVJmoC+N3fPBC5eYfkzq2p3kkcBW5J8paquGtax+8WwEWB+fr5nWZKk5Yx9xp/kwcBvAx9erk9V7e6+3gFcChy/Qt9NVbVQVQtzc3PjliVJWkWfSz3PB75SVbuGLUxyYJKD9k4DJwI39tifJGkCVg3+JBcDnwOOTrIryTndojNYcpknyWOTbO5mDwU+m+Q64AvA5VV15eRKlySNY5R39Zy5TPvZQ9q+CZzSTe8AntSzPknShDlkgyQ1xiEbHgBaHJZg1O9Z0v15xi9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNGeXD1i9MckeSGwfa/jLJ7iTbutcpy6x7UpKbk2xPcu4kC5ckjWeUM/6LgJOGtL+7qo7rXpuXLkxyAPAe4GTgGODMJMf0KVaS1N+qwV9VVwF3jbHt44HtVbWjqn4EXAKcNsZ2JEkT1OfD1t+Q5BXAVuBNVXX3kuWHAd8YmN8FPG25jSXZCGwEmJ+f71GW1kqLH/IuPRCMe3P3vcAvA8cBtwHv7FtIVW2qqoWqWpibm+u7OUnSMsYK/qq6vap+XFU/Af6Jxcs6S+0GjhiYP7xrkyTN0FjBn+QxA7MvA24c0u2LwFFJHpfkocAZwGXj7E+SNDmrXuNPcjFwAnBIkl3A24ATkhwHFLATeE3X97HA+6rqlKrak+QNwMeAA4ALq+qmqXwXkqSRrRr8VXXmkOb3L9P3m8ApA/Obgfu91VOSNDs+uStJjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JasyqH8QitWDDuZeP1G/neadOuRJp+jzjl6TGrBr8SS5MckeSGwfa/jbJV5Jcn+TSJA9fZt2dSW5Isi3J1kkWLkkazyhn/BcBJy1p2wI8oaqeCHwVePMK6z+nqo6rqoXxSpQkTdKqwV9VVwF3LWn7eFXt6WavBg6fQm2SpCmYxDX+VwFXLLOsgI8nuSbJxgnsS5LUU6939SR5C7AH+NAyXZ5ZVbuTPArYkuQr3V8Qw7a1EdgIMD8/36csSdIKxj7jT3I28CLgD6qqhvWpqt3d1zuAS4Hjl9teVW2qqoWqWpibmxu3LEnSKsYK/iQnAX8GvKSqvrdMnwOTHLR3GjgRuHFYX0nS2hnl7ZwXA58Djk6yK8k5wPnAQSxevtmW5IKu72OTbO5WPRT4bJLrgC8Al1fVlVP5LiRJI1v1Gn9VnTmk+f3L9P0mcEo3vQN4Uq/qJEkT55ANa2zUoQHA4QEkTYdDNkhSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjEM2NGRfhouYhfVen/RA4Rm/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JasxIwZ/kwiR3JLlxoO0RSbYkuaX7evAy657V9bklyVmTKlySNJ5Rz/gvAk5a0nYu8ImqOgr4RDf/M5I8Angb8DTgeOBty/2CkCStjZGCv6quAu5a0nwa8IFu+gPAS4es+kJgS1XdVVV3A1u4/y8QSdIa6nON/9Cquq2b/l/g0CF9DgO+MTC/q2uTJM3IRIZsqKpKUn22kWQjsBFgfn5+EmXt9xzCQNI09Dnjvz3JYwC6r3cM6bMbOGJg/vCu7X6qalNVLVTVwtzcXI+yJEkr6RP8lwF736VzFvAfQ/p8DDgxycHdTd0TuzZJ0oyM+nbOi4HPAUcn2ZXkHOA84AVJbgGe382TZCHJ+wCq6i7gHcAXu9fbuzZJ0oyMdI2/qs5cZtHzhvTdCrx6YP5C4MKxqpMkTZxP7kpSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGTGTIBmklD6ShJ0b9Xnaed+qUK5HG5xm/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmLGDP8nRSbYNvO5N8sYlfU5Ics9An7f2L1mS1MfYg7RV1c3AcQBJDgB2A5cO6fqZqnrRuPuRJE3WpC71PA+4taq+PqHtSZKmZFLBfwZw8TLLnpHkuiRXJDl2QvuTJI2pd/AneSjwEuBfhyy+Fjiyqp4E/APw0RW2szHJ1iRbv/Wtb/UtS5K0jEmc8Z8MXFtVty9dUFX3VtV93fRm4CFJDhm2karaVFULVbUwNzc3gbIkScNMIvjPZJnLPEkenSTd9PHd/u6cwD4lSWPq9dGLSQ4EXgC8ZqDttQBVdQFwOvC6JHuA7wNnVFX12ackqZ9ewV9V3wUeuaTtgoHp84Hz++xDkjRZPrkrSY3pdcYvaW1sOPfykfvuPO/UKVaiBwLP+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTE+ubuKfXliUpL2B57xS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmN7Bn2RnkhuSbEuydcjyJPn7JNuTXJ/kKX33KUka36Qe4HpOVX17mWUnA0d1r6cB7+2+SpJmYC0u9ZwGfLAWXQ08PMlj1mC/kqQhJnHGX8DHkxTwj1W1acnyw4BvDMzv6tpuG+yUZCOwEWB+fn4CZUltGnWYET+UvV2TOON/ZlU9hcVLOq9P8uxxNlJVm6pqoaoW5ubmJlCWJGmY3sFfVbu7r3cAlwLHL+myGzhiYP7wrk2SNAO9gj/JgUkO2jsNnAjcuKTbZcArunf3PB24p6puQ5I0E32v8R8KXJpk77b+paquTPJagKq6ANgMnAJsB74HvLLnPiVJPfQK/qraATxpSPsFA9MFvL7PfiRJk+OTu5LUGINfkhpj8EtSYwx+SWqMwS9JjZnUIG37nVEfa5ceqBzaoV2e8UtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqTBY/J2V9WVhYqK1bt461rkMxSOubQ0BMR5JrqmphlL6e8UtSY8YO/iRHJPlUki8luSnJnwzpc0KSe5Js615v7VeuJKmvPqNz7gHeVFXXJjkIuCbJlqr60pJ+n6mqF/XYjyRpgsY+46+q26rq2m76O8CXgcMmVZgkaTomco0/yQbgycDnhyx+RpLrklyR5NhJ7E+SNL7eH8SS5BeAfwPeWFX3Lll8LXBkVd2X5BTgo8BRy2xnI7ARYH5+vm9ZkqRl9DrjT/IQFkP/Q1X170uXV9W9VXVfN70ZeEiSQ4Ztq6o2VdVCVS3Mzc31KUuStII+7+oJ8H7gy1X1rmX6PLrrR5Lju/3dOe4+JUn99bnU85vAHwE3JNnWtf05MA9QVRcApwOvS7IH+D5wRq3HJ8YkqSFjB39VfRbIKn3OB84fdx+SpMnrfXNXkvbFqMOqOLTD9DhkgyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGOGSDpGY4XMQiz/glqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSY3oFf5KTktycZHuSc4csf1iSD3fLP59kQ5/9SZL6Gzv4kxwAvAc4GTgGODPJMUu6nQPcXVW/Arwb+Otx9ydJmow+Z/zHA9urakdV/Qi4BDhtSZ/TgA900x8BnpdkxQ9olyRNV5/gPwz4xsD8rq5taJ+q2gPcAzyyxz4lST2tmyEbkmwENnaz9yW5ecxNHQJ8ezJVTZR17Rvr2jcPuLoy3QvDK9Y15X2vpM+/45GjduwT/LuBIwbmD+/ahvXZleTBwC8Bdw7bWFVtAjb1qAeAJFuraqHvdibNuvaNde0b69o3rdfV51LPF4GjkjwuyUOBM4DLlvS5DDirmz4d+GRVVY99SpJ6GvuMv6r2JHkD8DHgAODCqropyduBrVV1GfB+4J+TbAfuYvGXgyRphnpd46+qzcDmJW1vHZj+AfA7ffYxht6Xi6bEuvaNde0b69o3TdcVr7xIUlscskGSGrPfBP8Iw0M8O8m1SfYkOX3JsrOS3NK9zlq67gzr+nGSbd1r6Y3xadf1p0m+lOT6JJ9IcuTAslker5XqmtrxGrG21ya5odv/ZwefVE/y5m69m5O8cD3UlWRDku8PHLML1rKugX4vT1JJFgbaZna8lqtr1scrydlJvjWw/1cPLJvsz2RVrfsXizePbwUeDzwUuA44ZkmfDcATgQ8Cpw+0PwLY0X09uJs+eNZ1dcvum+Hxeg7w893064APr5PjNbSuaR6vfajtFwemXwJc2U0f0/V/GPC4bjsHrIO6NgA3zup4df0OAq4CrgYW1sPxWqGumR4v4Gzg/CHrTvxncn854191eIiq2llV1wM/WbLuC4EtVXVXVd0NbAFOWgd1TdModX2qqr7XzV7N4nMYMPvjtVxd0zZKbfcOzB4I7L1BdhpwSVX9sKq+BmzvtjfruqZplCFbAN7B4hhdPxhom+nxWqGuaRq1rmEm/jO5vwT/KMNDTGPdaW/755JsTXJ1kpdOqKZx6joHuGLMddeqLpje8Rq5tiSvT3Ir8DfAH+/LujOoC+BxSf4nyX8nedaEahqpriRPAY6oqqWfcD7T47VCXTDD49V5eXeZ8yNJ9j4gO/HjtW6GbGjUkVW1O8njgU8muaGqbl3LApL8IbAA/NZa7nc1y9Q18+NVVe8B3pPk94G/4KcPKM7UMnXdBsxX1Z1Jngp8NMmxS/5CmIokDwLexeLli3Vjlbpmdrw6/wlcXFU/TPIaFge4fO40drS/nPGPMjzENNad6raranf3dQfwaeDJa1lXkucDbwFeUlU/3Jd1Z1DXNI/XyLUNuATY+1fHzI/ZsLq6Syl3dtPXsHiN+VfXqK6DgCcAn06yE3g6cFl3I3WWx2vZumZ8vKiqOwf+v78PeOqo6+6zadzImPSLxb9MdrB4I2jvjZFjl+l7Efe/ufs1Fm+KHNxNP2Id1HUw8LBu+hDgFobchJpWXSyG5q3AUUvaZ3q8VqhrasdrH2o7amD6xSw+oQ5wLD97s3IHk7tZ2aeuub11sHhTcfcs/u93/T/NT2+izvR4rVDXTI8X8JiB6ZcBV3fTE/+ZnMgPzVq8gFOAr3ah8Jau7e0snhUC/DqL176+y+JAcDcNrPsqFm8gbQdeuR7qAn4DuKH7D3ADcM4a1/VfwO3Atu512To5XkPrmvbxGrG2vwNu6ur61OAPLot/odwK3AycvB7qAl4+0H4t8OK1rGtJ30/TBeysj9dydc36eAF/1e3/uu7f8dcG1p3oz6RP7kpSY/aXa/ySpAkx+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5Jasz/AywQ9Af0drDxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ratio_good,bins=30,range=[0.1,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  2.,  5.,  1.,  7.,  7.,  7.,  3.,  5., 11., 10., 10., 13.,\n",
       "         6.,  6.,  5.,  5.,  2.,  2.,  1.,  2.,  2.,  3.,  0.,  2.,  0.,\n",
       "         0.,  1.,  0.,  0.]),\n",
       " array([0.1       , 0.11333333, 0.12666667, 0.14      , 0.15333333,\n",
       "        0.16666667, 0.18      , 0.19333333, 0.20666667, 0.22      ,\n",
       "        0.23333333, 0.24666667, 0.26      , 0.27333333, 0.28666667,\n",
       "        0.3       , 0.31333333, 0.32666667, 0.34      , 0.35333333,\n",
       "        0.36666667, 0.38      , 0.39333333, 0.40666667, 0.42      ,\n",
       "        0.43333333, 0.44666667, 0.46      , 0.47333333, 0.48666667,\n",
       "        0.5       ]),\n",
       " <a list of 30 Patch objects>)"
      ]
     },
     "execution_count": 846,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(ratio_bad,bins=30,range=[0.1,0.5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_bad=np.zeros(len(pic_bad))\n",
    "for n in range(len(pic_bad)):\n",
    "    Xtest=np.zeros(((1024//r)*(1024//r),2*r,2*r))\n",
    "\n",
    "    pic=pic_bad[n]\n",
    "    for i in range(1024//r-1):\n",
    "        for j in range(1024//r-1):\n",
    "            Xtest[i*1024//r+j]=pic[(i*r):(i*r+2*r),(j*r):(j*r+2*r)]\n",
    "\n",
    "    Temp=np.zeros(len(Xtest))\n",
    "    for i in range(len(Xtest)):\n",
    "        if Xtest[i].all():\n",
    "            Temp[i]=1\n",
    "    Xtest=Xtest[np.where(Temp==1)[0]]  \n",
    "    x_test=Xtest.reshape(Xtest.shape[0],-1)\n",
    "    y_test=np.array([0]).repeat(Xtest.shape[0])\n",
    "\n",
    "    #a better report instead of only accuracy\n",
    "    from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "    creport = lambda gt_vec,pred_vec: classification_report(gt_vec, pred_vec, \n",
    "                                                            target_names = [x.decode() for x in \n",
    "                                                                            class_le.classes_])\n",
    "\n",
    "    #knn\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    knn = KNeighborsClassifier()\n",
    "    knn.fit(x_train, y_train)\n",
    "    y_pred = knn.predict(x_test)\n",
    "    #print('Accuracy %2.2f%%' % (100*accuracy_score(y_test, y_pred)))\n",
    "    #print(creport(y_test, y_pred))\n",
    "\n",
    "    sum_bad[n]=sum(y_pred==0)\n",
    "    ratio_bad[n]=sum_bad[n]/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 820,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5462184873949579 0.5592417061611374\n"
     ]
    }
   ],
   "source": [
    "for n in range(int(min(min(sum_bad),min(sum_good))),int(max(max(sum_bad),max(sum_good)))):\n",
    "    if sum(sum_bad>n)/len(sum_bad) <= sum(sum_good<n)/len(sum_good):\n",
    "        break\n",
    "print(sum(sum_bad>n)/len(sum_bad),sum(sum_good<n)/len(sum_good))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
